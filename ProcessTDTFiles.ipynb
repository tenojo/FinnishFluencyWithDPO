{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255f2b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9164ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import OpenAI_lib as ol\n",
    "import time\n",
    "\n",
    "client = ol.get_client_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df70cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e42eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "from openai.types.responses import Response\n",
    "from openai.lib._parsing._responses import parse_response\n",
    "\n",
    "#Define wished output structure and method for prompting GPT\n",
    "class GeneratedTexts(BaseModel):\n",
    "    alku: str\n",
    "    teksti: str\n",
    "\n",
    "file_response = client.files.content()\n",
    "\n",
    "completions = [\n",
    "    parse_response(\n",
    "        response=Response\\\n",
    "            .model_validate(json.loads(line)['response']['body']),\n",
    "        text_format=GeneratedTexts,\n",
    "        input_tools=[]\n",
    "    )\\\n",
    "    .output_parsed\\\n",
    "    for line in file_response.read().splitlines() if line.strip()\n",
    "]\n",
    "\n",
    "pprint(completions)\n",
    "\n",
    "with open(\"data/GPTRegens/news-fi-2019.jsonl_regeneration_test_1.jsonl\", 'r') as reader:\n",
    "    for l in reader:\n",
    "        if len(l) > 0:\n",
    "            tester = json.loads(l.strip())\n",
    "\n",
    "pprint(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a10cd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "metadata = []\n",
    "for fn in os.listdir(\"data/TDT\"):\n",
    "    with open(\"data/TDT/\"+fn, 'r') as reader:\n",
    "        for l in reader:\n",
    "            if l.find(\"# sent_id = \") != -1:\n",
    "                metadata.append(l[12:-1])\n",
    "                continue\n",
    "            if l.find(\" text = \") != -1:\n",
    "                texts.append(l[8:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6d9933a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(texts) == len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "14a86ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15136\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b27bb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrs = []\n",
    "for n in metadata:\n",
    "    val = int(re.search(r'\\d+', n).start())\n",
    "    abbrs.append(n[:val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c1d12c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_docs = {x[:x.find('.')]:[] for x in metadata if x[0] != 'h'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3420ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "acrs = {\n",
    "    'wn' : 'wikinews-artikkeli',\n",
    "    'f' : 'kaunokirjallinnen teksti',\n",
    "    'fA' : 'kaunokirjallinnen teksti',\n",
    "    'fB' : 'kaunokirjallinnen teksti',\n",
    "    'fC' : 'kaunokirjallinnen teksti',\n",
    "    'fD' : 'kaunokirjallinnen teksti',\n",
    "    'fE' : 'kaunokirjallinnen teksti',\n",
    "    'fF' : 'kaunokirjallinnen teksti',\n",
    "    'b' : 'blogiteksti',\n",
    "    'u' : 'yliopisto uutinen',\n",
    "    'j' : 'lakiteksti',\n",
    "    'e' : 'parlamenttipuhe',\n",
    "    't' : 'talousuutinen',\n",
    "    'w' : 'wikipedia-artikkeli',\n",
    "    's' : 'opiskelijalehti-artikkeli',\n",
    "    'h' : 'esimerkki'\n",
    "}\n",
    "for a in set(abbrs):\n",
    "    acrs[a]\n",
    "\n",
    "ool = {\n",
    "    'wn' : 'otsikko',\n",
    "    'f' : 'otsikko',\n",
    "    'fA' : 'otsikko',\n",
    "    'fB' : 'otsikko',\n",
    "    'fC' : 'otsikko',\n",
    "    'fD' : 'otsikko',\n",
    "    'fE' : 'otsikko',\n",
    "    'fF' : 'otsikko',\n",
    "    'b' : 'otsikko',\n",
    "    'u' : 'otsikko',\n",
    "    'j' : 'otsikko',\n",
    "    'e' : 'ensimmäinen lause',\n",
    "    't' : 'otsikko',\n",
    "    'w' : 'enismmäinen lause',\n",
    "    's' : 'otsikko',\n",
    "    'h' : 'esimerkki'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e8c67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,n in enumerate(metadata):\n",
    "    if n[0] != 'h':\n",
    "        full_docs[n[:n.find('.')]] = full_docs[n[:n.find('.')]] + [texts[i]]\n",
    "\n",
    "full_docs_list = []\n",
    "for f in full_docs:\n",
    "    sents = full_docs[f]\n",
    "    full_docs_list.append({'id':f, 'register':acrs[f[:int(re.search(r'\\d+', f).start())]], 'first_line_type':ool[f[:int(re.search(r'\\d+', f).start())]], 'first_line':sents[0], 'text':' '.join(sents[1:]), 'text_sent_amount':len(sents)-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9e8daa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'b104', 'register': 'blogiteksti', 'first_line_type': 'otsikko', 'first_line': ' Taas teatteriin', 'text': ' Tänäänkin pitäisi mennä teatteriin.  Varasin pupulle ja minulle sekä sille sisarentyttärelleni, joka pääsi Turkuun lakia lukemaan, liput kaupunginteatterin Laulavat sadepisarat -musikaaliin.  Sen jälkeen voisi mennä vaikkapa Suxessiin oluelle.  Muita matkalla sinne?', 'text_sent_amount': 4}\n"
     ]
    }
   ],
   "source": [
    "print(full_docs_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f6a83c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674\n"
     ]
    }
   ],
   "source": [
    "print(len(full_docs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d52c5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"TDT_doc_data.jsonl\", 'w') as writer:\n",
    "    for f in full_docs_list:\n",
    "        writer.write(json.dumps(f)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
